import pandas as pd
import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Lasso
from xgboost import XGBRegressor

from utils import evaluate_model
from utils import tune_model

data = pd.read_csv("data/processed/clean_train.csv")

'''
çº¿æ€§å›å½’(Linear Regression)
MAE
'''
# 
y = data['SalePrice']
X = data.drop('SalePrice', axis = 1)

X_encoded = pd.get_dummies(X)

# logå¤‰æ›å‡¦ç†è¿½åŠ 
y_log = np.log1p(y)

# logå¤‰æ›æŠœã‘
# X_train,X_val,y_train,y_val = train_test_split(X_encoded,y,test_size=0.2,random_state=42)
# logå¤‰æ›ã‚ã‚Šã€y_logã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
X_train,X_val,y_train,y_val = train_test_split(X_encoded,y_log,test_size=0.2,random_state=42)
print("-----------------------------")
print("Sale Price Mean:", y.mean())

'''
ä¸‰ç§æ¨¡å‹ç»“æœæ¯”è¾ƒ
MSE
'''
results = []

# Linear Regression
results.append(evaluate_model(
    "LinearRegression",
    LinearRegression(),
    X_train, X_val, y_train, y_val
))

# Random Forest
results.append(evaluate_model(
    "RandomForest",
    RandomForestRegressor(random_state=42),
    X_train, X_val, y_train, y_val
))

# ------ãƒ‘ãƒ¼ãƒ©ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–è¿½åŠ ï¼ˆ4/10ï¼‰--------
rf_param_grid = {
    "n_estimators": [100, 200],
    "max_depth": [None, 5, 20],
    "min_samples_split": [2, 5, 10]
}
best_rf = tune_model(
    RandomForestRegressor(random_state=42), 
    rf_param_grid, 
    X_train, 
    y_train
)
results.append(evaluate_model(
    "Tuned RandomForest",
    best_rf,
    X_train, X_val, y_train, y_val
))

# XGBoost
results.append(evaluate_model(
    "XGBoost",
    XGBRegressor(random_state=42, verbosity=0),
    X_train, X_val, y_train, y_val
))

# ------ãƒ‘ãƒ¼ãƒ©ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–è¿½åŠ ï¼ˆ4/10ï¼‰--------
xgb_param_grid = {
    "n_estimators": [100, 200],            # æ£®æ—ä¸­æ ‘çš„æ•°é‡
    "max_depth": [3, 6, 10],               # æ¯æ£µæ ‘çš„æœ€å¤§æ·±åº¦
    "learning_rate": [0.01, 0.1],          # å­¦ä¹ ç‡ï¼ˆè¶Šå°è¶Šç¨³è¶Šæ…¢ï¼‰
    "subsample": [0.8, 1.0],               # æ¯æ£µæ ‘çš„è®­ç»ƒæ ·æœ¬æ¯”ä¾‹ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
    "colsample_bytree": [0.8, 1.0],        # æ¯æ£µæ ‘ç”¨çš„ç‰¹å¾æ¯”ä¾‹
    "reg_alpha": [0, 1],                   # L1æ­£åˆ™åŒ–å¼ºåº¦
    "reg_lambda": [1, 10]                  # L2æ­£åˆ™åŒ–å¼ºåº¦
}
best_xgb = tune_model(
    XGBRegressor(random_state=42, verbosity=0),
    xgb_param_grid,
    X_train, 
    y_train
)
results.append(evaluate_model(
    "Tuned XGBoost",
    best_xgb,
    X_train, X_val, y_train, y_val
))

# Output result comparison
result_df = pd.DataFrame(results)
result_df = result_df.sort_values(by="Validation MSE")

print("-----------------------------Model Comparison")
print("\nğŸ“Š Model Comparison Result:")
print(result_df.to_string(index=False))
