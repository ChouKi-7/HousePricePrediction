import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Lasso
from xgboost import XGBRegressor
import matplotlib.pyplot as plt


from utils import tune_model

data = pd.read_csv("data/processed/clean_train.csv")

'''
çº¿æ€§å›å½’(Linear Regression)
MAE
'''
# 
y = data['SalePrice']
X = data.drop('SalePrice', axis = 1)

X_encoded = pd.get_dummies(X)

# logå¤‰æ›å‡¦ç†è¿½åŠ 
y_log = np.log1p(y)

# logå¤‰æ›æŠœã‘
# X_train,X_val,y_train,y_val = train_test_split(X_encoded,y,test_size=0.2,random_state=42)
# logå¤‰æ›ã‚ã‚Šã€y_logã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
X_train,X_val,y_train,y_val = train_test_split(X_encoded,y_log,test_size=0.2,random_state=42)
print("-----------------------------Linear")
print("Sale Price Mean:", y.mean())

#
model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_val)
MAE = mean_absolute_error(y_val, y_pred)
print("Validation MAE:", MAE)

train_pred = model.predict(X_train)
train_MAE = mean_absolute_error(y_train, train_pred)

print("Train MAE: ",train_MAE)
print("Overfit Gap Rate:",(MAE - train_MAE) / MAE * 100)

y_pred_real = np.expm1(y_pred)
y_val_real = np.expm1(y_val)
MAE_real = mean_absolute_error(y_val_real, y_pred_real)
print("MAE after log inverse (çœŸå®æˆ¿ä»·ä¸‹):", round(MAE_real, 2))

print("-----------------------------")

'''
Ridgeã‚’è©¦ã™
2025/4/11
'''
# LinearRegressionã‚’Ridgeã«åˆ‡ã‚Šæ›¿ãˆ
ridge_model = Ridge(alpha=0.1)
ridge_model.fit(X_train,y_train)

y_pred_ridge = ridge_model.predict(X_val)

# è¿˜åŸä¸ºçœŸå®ä»·æ ¼
y_pred_real_ridge = np.expm1(y_pred_ridge)
# y_val_real_ridge = np.expm1(y_val)

MAE_ridge = mean_absolute_error(y_val_real, y_pred_real_ridge)
MSE_ridge = mean_squared_error(y_val_real, y_pred_real_ridge)

print("-----------------------------Ridge")
print("âœ… Ridge Regression ç»“æœ:")
print("MAE_RIDGE (çœŸå®ä»·æ ¼):", round(MAE_ridge, 2))
print("MSE_RIDGE (çœŸå®ä»·æ ¼):", round(MSE_ridge, 2))
print("-----------------------------")

'''
paramæœ€é©åŒ–
'''
ridge_param_grid = {"alpha":[0.01,0.1,1.0,10.0,20.0,50.0]}

best_ridge = tune_model(
    Ridge(),
    ridge_param_grid,
    X_train,
    y_train
)
y_pred_ridge_best = best_ridge.predict(X_val)

y_pred_real_ridge_best = np.expm1(y_pred_ridge_best)
# y_val_real_ridge_best = np.expm1(y_val)

MAE_ridge_best = mean_absolute_error(y_val_real,y_pred_real_ridge_best)
MSE_ridge_best = mean_squared_error(y_val_real,y_pred_real_ridge_best)

print("Ridge Regression (Best Alpha)")
print("MAE_RIDGE_BEST:", round(MAE_ridge_best, 2))
print("MSE_RIDGE_BEST:", round(MSE_ridge_best, 2))
print("-----------------------------")


# ---------- Lasso ----------
lasso_model = Lasso(max_iter=10000)
lasso_model.fit(X_train, y_train)

y_pred_lasso = lasso_model.predict(X_val)

# è¿˜åŸä¸ºçœŸå®ä»·æ ¼
y_pred_real_lasso = np.expm1(y_pred_lasso)
# y_val_real_lasso = np.expm1(y_val)

MAE_lasso = mean_absolute_error(y_val_real,y_pred_real_lasso)
MSE_lasso = mean_squared_error(y_val_real,y_pred_real_lasso)

print("-----------------------------Lasso")
print("âœ… Lasso ç»“æœ:")
print("MAE_LASSO (çœŸå®ä»·æ ¼):", round(MAE_lasso, 2))
print("MSE_LASSO (çœŸå®ä»·æ ¼):", round(MSE_lasso, 2))
print("-----------------------------")

lasso_param_grid = {
    "alpha": [0.001, 0.01, 0.1, 1.0, 10.0]
}
best_lasso = tune_model(
    Lasso(max_iter=10000),  # é˜²æ­¢æ”¶æ•›é—®é¢˜
    lasso_param_grid,
    X_train,
    y_train 
)
y_pred_lasso_best = best_lasso.predict(X_val)

y_pred_real_lasso_best = np.expm1(y_pred_lasso_best)

MAE_lasso_best = mean_absolute_error(y_val_real,y_pred_lasso_best)
MSE_lasso_best = mean_squared_error(y_val_real,y_pred_lasso_best)

print("Lasso (Best Alpha)")
print("MAE_LASSO_BEST:", round(MAE_lasso_best, 2))
print("MSE_LASSO_BEST:", round(MSE_lasso_best, 2))

coef = best_lasso.coef_
nonzero_idx = np.where(coef != 0)[0]
selected_features = X_train.columns[nonzero_idx]

print(f"ğŸ“Œ é€‰ä¸­çš„ç‰¹å¾æ•°é‡: {len(selected_features)} / {len(coef)}")
print("ğŸ¯ è¢«ä¿ç•™ä¸‹æ¥çš„ç‰¹å¾ï¼ˆéƒ¨åˆ†ï¼‰ï¼š")
print(selected_features[:20])  
print("-----------------------------")

# ---------- ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰ã‚’å¯è¦–åŒ– ----------
# å„ãƒ¢ãƒ‡ãƒ«ï¼ˆLinear, Ridge, Lassoãªã©ï¼‰ã®äºˆæ¸¬èª¤å·®ï¼ˆMAEï¼‰ã‚’æ¯”è¼ƒã—ã€
# ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒæœ€ã‚‚å®‰å®šã—ã¦ã„ã‚‹ã‹ã€éå­¦ç¿’ã—ã¦ã„ãªã„ã‹ã‚’ç›´æ„Ÿçš„ã«ç¢ºèªã™ã‚‹ã€‚
# èµ¤ã„ç ´ç·šã¯æœ€å°ã®MAEãƒ©ã‚¤ãƒ³ï¼ˆæœ€ã‚‚è‰¯ã„ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’ç¤ºã™ã€‚
model_names = ['Linear', 'Ridge', 'Ridge(Tuned)', 'Lasso', 'Lasso(Tuned)']
maes = [MAE_real, MAE_ridge, MAE_ridge_best, MAE_lasso, MAE_lasso_best]

plt.figure(figsize=(10, 6))
plt.bar(model_names, maes, color='skyblue')
plt.ylabel("MAE(real)")
plt.title("MAE Comparison Across Models")
plt.axhline(y=min(maes), color='red', linestyle='--', label='Minimum MAE')
plt.legend()
plt.tight_layout()
plt.show()